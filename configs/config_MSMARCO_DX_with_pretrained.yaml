max_learning_rate: 1.28e-4
min_learning_rate: 5.12e-6
warmup_steps: 0
architecture: DiffFormer
dataset: MSMARCO
max_iters: 20000
batch_size: 16
save_every: 4000
eval_every: 4000
size: 122M
pretrain: True
train_file: third_party/MSMARCO/train_v2.1.json
val_file: third_party/MSMARCO/dev_v2.1.json
test_file: third_party/MSMARCO/eval_v2.1_public.json
work_dir: DiffFormer_MSMARCO_with_pretrained
tokenizer_name: "HuggingFaceTB/SmolLM-135M"
