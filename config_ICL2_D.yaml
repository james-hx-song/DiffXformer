# @format

architecture: "Transformer" # or "DiffFormer"
learning_rate: 0.0001
max_iters: 20000
batch_size: 256
save_every: 1000
eval_every: 1000
num_val_samples: 1000

# Dataset and model configuration
d_dim: 20
hidden_d_dim: 5
n_examples: 41
tau: 1.0
